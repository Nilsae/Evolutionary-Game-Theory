{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "87d25348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self,network,Z_func, id):\n",
    "        self.strategy = None # A or B\n",
    "        self.next_strategy = None\n",
    "        self.previous_strategy = None\n",
    "        self.neighbors_id = []\n",
    "        self.Z_func = Z_func\n",
    "        self.network = network\n",
    "        self.type = None #=type = update rule(coordinating , anti_coordinating\n",
    "        self.id = id\n",
    "   \n",
    "\n",
    "    def __coordinating(self, agents,Z_func,threshold):\n",
    "        A_neighbors_count = 0\n",
    "        B_neighbors_count = 0\n",
    "        total_neighbors_count = len(self.neighbors_id)\n",
    "        neighbors = []\n",
    "        for neighbor_id in self.neighbors_id:\n",
    "            if agents[neighbor_id].strategy ==\"A\":\n",
    "                A_neighbors_count= A_neighbors_count+1\n",
    "            else :\n",
    "                B_neighbors_count = B_neighbors_count+1\n",
    "        # if self.binary_threshold ==\"normal\":\n",
    "#         print(\"co: \"+str(A_neighbors_count)+\" As and \"+str(B_neighbors_count)+\" Bs\")\n",
    "        if A_neighbors_count >= B_neighbors_count:\n",
    "            self.next_strategy = \"A\"\n",
    "        else:\n",
    "            self.next_strategy = \"B\"\n",
    "   \n",
    "    def __anti_coordinating(self, agents,Z_func,threshold):\n",
    "        A_neighbors_count = 0\n",
    "        B_neighbors_count = 0\n",
    "        total_neighbors_count = len(self.neighbors_id)\n",
    "        for neighbor_id in self.neighbors_id:\n",
    "            if agents[neighbor_id].strategy ==\"A\":\n",
    "                A_neighbors_count= A_neighbors_count+1\n",
    "            else :\n",
    "                B_neighbors_count = B_neighbors_count+1\n",
    "        # if self.binary_threshold == \"normal\":\n",
    "#         print(\"anti: \"+str(A_neighbors_count)+\" As and \"+str(B_neighbors_count)+\" Bs\")\n",
    "        if A_neighbors_count <= B_neighbors_count:\n",
    "            self.next_strategy = \"A\"\n",
    "        else:\n",
    "            self.next_strategy = \"B\"\n",
    "\n",
    "    def decide_next_strategy(self, agent,Z_func,threshold):\n",
    "        if self.type == \"+\":\n",
    "            self.__coordinating(agent,Z_func,threshold)\n",
    "\n",
    "        elif self.type == \"-\":\n",
    "            self.__anti_coordinating(agent,Z_func,threshold)\n",
    "\n",
    "    def update_strategy(self):\n",
    "        self.strategy = self.next_strategy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d68a6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from csv import writer\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plus(idd, number, population):\n",
    "    if idd + number >= population:\n",
    "        return idd + number - population - 1\n",
    "    else:\n",
    "        return idd + number\n",
    "\n",
    "\n",
    "def minus(idd, number, population):\n",
    "    if idd + number <= 0:\n",
    "        return population - idd\n",
    "    else:\n",
    "        return idd - 1\n",
    "\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, population, z_func, strategy_list, type_list, activated_list, desired_eq):\n",
    "        self.network = None\n",
    "        self.Z_func = z_func\n",
    "        self.population = population\n",
    "        self.strategy_list = strategy_list\n",
    "        self.type_list = type_list\n",
    "        self.activated_list = activated_list\n",
    "        self.desired_eq = desired_eq\n",
    "        self.agents = self.__generate_agents()\n",
    "\n",
    "    def __generate_agents(self):\n",
    "        self.network = nx.circulant_graph(self.population, [1])  # ring only\n",
    "        agents = [Agent(self.network, self.Z_func, i) for i in range(self.population)]\n",
    "        for index, focal in enumerate(agents):\n",
    "            neighbors_id = list(self.network[index])\n",
    "#             print(neighbors_id)\n",
    "            for nb_id in neighbors_id:\n",
    "                focal.neighbors_id.append(nb_id)\n",
    "        return agents\n",
    "\n",
    "    def __initialize_label_A_or_B(self):\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            focal.strategy = self.strategy_list[index]\n",
    "\n",
    "    def determine_coordinator_or_anticoordinator(self, co_list):\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if self.type_list[index] == '+':\n",
    "                focal.type = \"+\"\n",
    "            else:\n",
    "                focal.type = \"-\"\n",
    "\n",
    "    def __take_snapshot(self, timestep, equilibrated):\n",
    "\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if focal.strategy == \"A\":\n",
    "                self.network.nodes[index][\"strategy\"] = \"A\"\n",
    "            else:\n",
    "                self.network.nodes[index][\"strategy\"] = \"B\"\n",
    "\n",
    "        def color(i):\n",
    "            if self.network.nodes[i][\"strategy\"] == \"A\":\n",
    "                return 'cyan'\n",
    "            else:\n",
    "                return 'pink'\n",
    "\n",
    "        color = dict((i, color(i)) for i in self.network.nodes())\n",
    "        # if self.network_type == \"ring\":\n",
    "        pos = nx.circular_layout(self.network)\n",
    "        #\n",
    "        # else:\n",
    "        #     pos = nx.spring_layout(self.network)\n",
    "\n",
    "        nx.draw_networkx_edges(self.network, pos)\n",
    "        nx.draw_networkx_nodes(self.network, pos, node_color=list(color.values()), node_size=500)\n",
    "        labels = {}\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if focal.type == \"+\":\n",
    "                labels[index] = f\"{index},+\"\n",
    "            else:\n",
    "                labels[index] = f\"{index},-\"\n",
    "\n",
    "        nx.draw_networkx_labels(self.network, pos, labels, font_size=16)\n",
    "        eq_str = \"\"\n",
    "        if equilibrated:\n",
    "            eq_str = \"Equilibrated!\"\n",
    "        plt.title(f\"t={timestep}  {eq_str}\", fontsize=20)\n",
    "        plt.axis = \"off\"\n",
    "        time_past_eq = -1\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(f\"snap_t={timestep}.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def has_equilibrated(self):\n",
    "        equilibrated = 1\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if focal.strategy != focal.previous_strategy:\n",
    "                equilibrated = 0\n",
    "                break\n",
    "\n",
    "        return equilibrated\n",
    "\n",
    "    def one_episode(self, time_steps, threshold):\n",
    "        reached_desired = 0\n",
    "        self.__initialize_label_A_or_B()\n",
    "        self.determine_coordinator_or_anticoordinator(self.type_list)\n",
    "        equilibrated = -1\n",
    "        equilibrated_array = []\n",
    "        current_strategy_list = self.strategy_list\n",
    "        prev_i = -2\n",
    "        for t in range(time_steps):\n",
    "#             for f in self.agents:\n",
    "#                 print(\"id: \"+ str(f.id)+\" type: \"+f.type+\" strategy: \"+f.strategy+\" willing to be: \"+str(f.next_strategy))\n",
    "            for i in range(self.population):\n",
    "                self.agents[i].previous_strategy = self.agents[i].strategy\n",
    "                # if(t == time_steps-1):\n",
    "                \n",
    "                (self.agents[i]).decide_next_strategy(self.agents, self.Z_func, threshold)\n",
    "#                 print(\"next strategy in this timestep is decided for everyone!\")\n",
    "                current_strategy_list[i] = self.agents[i].strategy\n",
    "                reached_desired = (self.strategy_list == current_strategy_list)\n",
    "            # RANDOM AGENT TO BE ACTIVATED\n",
    "            # index_list = rnd.sample(range(self.population), k = 1)#########GGG#####\n",
    "            # index = index_list[0]\n",
    "            # AGENT TO BE ACTIVATED UNDER OUR POLICY:\n",
    "            index = self.activate_policy(prev_i)\n",
    "            prev_i = index\n",
    "            print(\"in timestep \"+str(t)+\" selected: agent \"+str(index))\n",
    "            \n",
    "            # if index!=0 and index!= self.population-1:\n",
    "            if index != -1:\n",
    "                # for index in self.cooperators: (everybody is cooperating)\n",
    "#                 (self.agents[index]).decide_next_strategy(self.agents, self.Z_func, threshold)\n",
    "#                 print(\"selected agent next strategy: \"+self.agents[index].next_strategy )\n",
    "                # for index in self.cooperators:\n",
    "                (self.agents[index]).update_strategy()\n",
    "                # self.agents[index].next_strategy = (self.agents[index]).strategy\n",
    "            else:\n",
    "                print (\"no one found\\n\")\n",
    "                if self.has_equilibrated():\n",
    "                    break\n",
    "#                 else:\n",
    "#                 self.activated_list = np.zeros(self.population)\n",
    "            equilibrated = self.has_equilibrated()\n",
    "            self.__take_snapshot(t, equilibrated)\n",
    "            print(\"selected agent : \"+str(index))\n",
    "            equilibrated_array.append(equilibrated)\n",
    "        eq_time = -1\n",
    "\n",
    "        new_result = pd.DataFrame(\n",
    "            {'reached_desired?': [reached_desired], 'Equilibrated?': [equilibrated], 'types': [self.type_list],\n",
    "             'initial strategy set': [self.strategy_list], 'final strategy set': [current_strategy_list],\n",
    "             'equilibration time': [eq_time]})\n",
    "        return new_result, equilibrated, eq_time, reached_desired\n",
    "\n",
    "    def activate_policy(self,prev_i):\n",
    "        c1 = []\n",
    "        c2 = []\n",
    "        c3 = []\n",
    "        for agent in self.agents:\n",
    "            w = (agent.strategy == self.desired_eq[agent.id])\n",
    "            B = (agent.strategy != agent.next_strategy)\n",
    "#             print(\"w=\"+str(w),\"B = \"+str(B))\n",
    "            if B == 1:\n",
    "                if agent.strategy == 'B' and agent.type == '+' \\\n",
    "                        and (self.strategy_list[plus(agent.id, 1, self.population)] == 'A' \\\n",
    "                             or self.strategy_list[\n",
    "                                 minus(agent.id, 1, self.population)] == 'A') and w==0:  # if agent[i+1]= A or agent[i-1] = A:\n",
    "                    c3.append(agent.id)  # add agent i to c3\n",
    "                elif (agent.strategy == 'B') and \\\n",
    "                     ((self.strategy_list[plus(agent.id, 1, self.population)] == 'B' and \\\n",
    "                       self.type_list[plus(agent.id, 1, self.population)] == '-' and \\\n",
    "                       self.strategy_list[plus(agent.id, 2, self.population)] == 'A' and \\\n",
    "                       self.type_list[plus(agent.id, 2, self.population)] == '-') or \\\n",
    "                      (self.strategy_list[minus(agent.id, 1, self.population)] == 'B' and \\\n",
    "                       self.type_list[minus(agent.id, 1, self.population)] == '-' and \\\n",
    "                       self.strategy_list[minus(agent.id, 2, self.population)] == 'A' and \\\n",
    "                       self.type_list[minus(agent.id, 2,\n",
    "                       self.population)] == '-')) and w==0:  # else if (agent[i+1] = B- and agent[i+2] = A-) or (agent[i-1] = B- and agent[i-2] = A-):\n",
    "                    c3.append(agent.id)  # add agent i to c3\n",
    "                elif (agent.strategy == 'A' and agent.type == '-') and \\\n",
    "                        ((self.strategy_list[plus(agent.id, 1, self.population)] == 'A' and \\\n",
    "                          self.type_list[plus(agent.id, 1, self.population)] == '-') or \\\n",
    "                         (self.strategy_list[minus(agent.id, 1, self.population)] == 'A' and \\\n",
    "                          self.type_list[minus(agent.id, 1, self.population)] == '-')) and w==0:\n",
    "                    c3.append(agent.id)  # else if agent i = A- and(agent i+1 = A- or agent i-1 = A-)\n",
    "                    # add agent i to c3\n",
    "                else:\n",
    "                    if w == 0:\n",
    "                        c1.append(agent.id)\n",
    "                    else:\n",
    "                        c2.append(agent.id)\n",
    "        print(\"c1: \"+str(c1)+\" c2: \"+str(c2)+\" c3: \"+str(c3))\n",
    "        print(\"agents activated so far: \"+ str(self.activated_list))\n",
    "        for i in range(self.population):\n",
    "            if i in c1 and i!= prev_i:\n",
    "                self.activated_list[i] =self.activated_list[i]+ 1\n",
    "                return i\n",
    "        for i in range(self.population):\n",
    "            if i in c2 and self.activated_list[i] <= 2 and i!= prev_i:\n",
    "                self.activated_list[i] =self.activated_list[i]+ 1\n",
    "                return i\n",
    "        for i in range(self.population):\n",
    "            if i in c3 and i!= prev_i:\n",
    "                self.activated_list[i] =self.activated_list[i]+ 1\n",
    "                return i\n",
    "            \n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "29964406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1: [] c2: [1, 6] c3: [0, 4, 7]\n",
      "agents activated so far: [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 0 selected: agent 1\n",
      "selected agent : 1\n",
      "c1: [] c2: [2, 6] c3: [0, 4, 7]\n",
      "agents activated so far: [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 1 selected: agent 2\n",
      "selected agent : 2\n",
      "c1: [] c2: [3, 6] c3: [0, 1, 4, 7]\n",
      "agents activated so far: [0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 2 selected: agent 3\n",
      "selected agent : 3\n",
      "c1: [] c2: [6] c3: [0, 1, 7]\n",
      "agents activated so far: [0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "in timestep 3 selected: agent 6\n",
      "selected agent : 6\n",
      "c1: [] c2: [] c3: [0, 1]\n",
      "agents activated so far: [0. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "in timestep 4 selected: agent 0\n",
      "selected agent : 0\n",
      "c1: [] c2: [8] c3: [1]\n",
      "agents activated so far: [1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "in timestep 5 selected: agent 8\n",
      "selected agent : 8\n",
      "c1: [] c2: [0] c3: [1]\n",
      "agents activated so far: [1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "in timestep 6 selected: agent 0\n",
      "selected agent : 0\n",
      "c1: [8] c2: [] c3: [1]\n",
      "agents activated so far: [2. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "in timestep 7 selected: agent 8\n",
      "selected agent : 8\n",
      "c1: [] c2: [] c3: [0, 1]\n",
      "agents activated so far: [2. 1. 1. 1. 0. 0. 1. 0. 2.]\n",
      "in timestep 8 selected: agent 0\n",
      "selected agent : 0\n",
      "c1: [] c2: [8] c3: [1]\n",
      "agents activated so far: [3. 1. 1. 1. 0. 0. 1. 0. 2.]\n",
      "in timestep 9 selected: agent 8\n",
      "selected agent : 8\n",
      "c1: [] c2: [0] c3: [1]\n",
      "agents activated so far: [3. 1. 1. 1. 0. 0. 1. 0. 3.]\n",
      "in timestep 10 selected: agent 1\n",
      "selected agent : 1\n",
      "c1: [] c2: [] c3: []\n",
      "agents activated so far: [3. 2. 1. 1. 0. 0. 1. 0. 3.]\n",
      "in timestep 11 selected: agent -1\n",
      "no one found\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4017/3260953646.py:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_result)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from numpy import zeros\n",
    "import random\n",
    "import  pandas as pd\n",
    "import itertools\n",
    "from pandas import concat\n",
    "\n",
    "\n",
    "def main():\n",
    "    population = 9 # number of agents\n",
    "    num_episode = 1    # Number of total episode in a single simulation for taking ensemble average\n",
    "    time_steps =30\n",
    "    threshold = 1/2\n",
    "    Z_func = \"A\" # the next strategy if number of A-playing neighbors equlas B-playing ones\n",
    "    always_equilibrates = 1\n",
    "    global new_result\n",
    "    result = pd.DataFrame({'reached_desired?': [],'Equilibrated?': [],'types': [],'initial strategy set': [],'final strategy set': [],'equilibration time': []})\n",
    "    # algorithm does not work on(pop=9): (loops :))\n",
    "    desired_eq = ['A', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A'] #desired equilibrium strategy of the agents\n",
    "    type_list = ['+', '+', '-', '-', '-', '+', '-', '-', '-'] #coordinator or anticoordinator listed identified by + and - signs\n",
    "    initial_strategy  =['B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A'] #initial strategy of the agents\n",
    "    #it works on: (original example ;))\n",
    "#     desired_eq = ['A', 'B', 'A', 'A', 'B', 'A', 'A', 'A']  # desired equilibrium strategy of the agents\n",
    "#     type_list = ['+', '-', '-', '+', '-', '-', '+', '+']  # coordinator or anticoordinator listed identified by + and - signs\n",
    "#     initial_strategy = ['B', 'A', 'B', 'A', 'A', 'B', 'A','B']  # initial strategy of the agents# selection = [i for i in range(population)]\n",
    "\n",
    "    # selection = [i for i in range(population)]\n",
    "    activated_list = zeros(population)\n",
    "    simulation = Simulation(population, Z_func, initial_strategy, type_list,activated_list, desired_eq)\n",
    "    new_result,equilibrated,eq_time,reached_desired = simulation.one_episode(time_steps, threshold)\n",
    "#     result = pd.DataFrame.from_records\n",
    "    result = result.append(new_result)\n",
    "    result.to_csv(f\"newfile.csv\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003d130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be5a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671daee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87d25348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self,network,Z_func, id):\n",
    "        self.strategy = None # A or B\n",
    "        self.next_strategy = None\n",
    "        self.previous_strategy = None\n",
    "        self.neighbors_id = []\n",
    "        self.Z_func = Z_func\n",
    "        self.network = network\n",
    "        self.type = None #=type = update rule(coordinating , anti_coordinating\n",
    "        self.id = id\n",
    "   \n",
    "\n",
    "    def __coordinating(self, agents,Z_func,threshold):\n",
    "        A_neighbors_count = 0\n",
    "        B_neighbors_count = 0\n",
    "        total_neighbors_count = len(self.neighbors_id)\n",
    "        neighbors = []\n",
    "        for neighbor_id in self.neighbors_id:\n",
    "            if agents[neighbor_id].strategy ==\"A\":\n",
    "                A_neighbors_count= A_neighbors_count+1\n",
    "            else :\n",
    "                B_neighbors_count = B_neighbors_count+1\n",
    "        # if self.binary_threshold ==\"normal\":\n",
    "#         print(\"co: \"+str(A_neighbors_count)+\" As and \"+str(B_neighbors_count)+\" Bs\")\n",
    "        if A_neighbors_count >= B_neighbors_count:\n",
    "            self.next_strategy = \"A\"\n",
    "        else:\n",
    "            self.next_strategy = \"B\"\n",
    "   \n",
    "    def __anti_coordinating(self, agents,Z_func,threshold):\n",
    "        A_neighbors_count = 0\n",
    "        B_neighbors_count = 0\n",
    "        total_neighbors_count = len(self.neighbors_id)\n",
    "        for neighbor_id in self.neighbors_id:\n",
    "            if agents[neighbor_id].strategy ==\"A\":\n",
    "                A_neighbors_count= A_neighbors_count+1\n",
    "            else :\n",
    "                B_neighbors_count = B_neighbors_count+1\n",
    "        # if self.binary_threshold == \"normal\":\n",
    "#         print(\"anti: \"+str(A_neighbors_count)+\" As and \"+str(B_neighbors_count)+\" Bs\")\n",
    "        if A_neighbors_count <= B_neighbors_count:\n",
    "            self.next_strategy = \"A\"\n",
    "        else:\n",
    "            self.next_strategy = \"B\"\n",
    "\n",
    "    def decide_next_strategy(self, agent,Z_func,threshold):\n",
    "        if self.type == \"+\":\n",
    "            self.__coordinating(agent,Z_func,threshold)\n",
    "\n",
    "        elif self.type == \"-\":\n",
    "            self.__anti_coordinating(agent,Z_func,threshold)\n",
    "\n",
    "    def update_strategy(self):\n",
    "        self.strategy = self.next_strategy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d68a6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from csv import writer\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plus(idd, number, population):\n",
    "    if idd + number >= population:\n",
    "        return idd + number - population - 1\n",
    "    else:\n",
    "        return idd + number\n",
    "\n",
    "\n",
    "def minus(idd, number, population):\n",
    "    if idd + number <= 0:\n",
    "        return population - idd\n",
    "    else:\n",
    "        return idd - 1\n",
    "\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, population, z_func, strategy_list, type_list, activated_list, desired_eq,initial_string):\n",
    "        self.network = None\n",
    "        self.Z_func = z_func\n",
    "        self.population = population\n",
    "        self.strategy_list = strategy_list\n",
    "        self.type_list = type_list\n",
    "        self.activated_list = activated_list\n",
    "        self.desired_eq = desired_eq\n",
    "        self.agents = self.__generate_agents()\n",
    "        self.initial_string =initial_string\n",
    "    def __generate_agents(self):\n",
    "        self.network = nx.circulant_graph(self.population, [1])  # ring only\n",
    "        agents = [Agent(self.network, self.Z_func, i) for i in range(self.population)]\n",
    "        for index, focal in enumerate(agents):\n",
    "            neighbors_id = list(self.network[index])\n",
    "#             print(neighbors_id)\n",
    "            for nb_id in neighbors_id:\n",
    "                focal.neighbors_id.append(nb_id)\n",
    "        return agents\n",
    "\n",
    "    def __initialize_label_A_or_B(self):\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            focal.strategy = self.strategy_list[index]\n",
    "\n",
    "    def determine_coordinator_or_anticoordinator(self, co_list):\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if self.type_list[index] == '+':\n",
    "                focal.type = \"+\"\n",
    "            else:\n",
    "                focal.type = \"-\"\n",
    "\n",
    "    def __take_snapshot(self, timestep, equilibrated):\n",
    "\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if focal.strategy == \"A\":\n",
    "                self.network.nodes[index][\"strategy\"] = \"A\"\n",
    "            else:\n",
    "                self.network.nodes[index][\"strategy\"] = \"B\"\n",
    "\n",
    "        def color(i):\n",
    "            if self.network.nodes[i][\"strategy\"] == \"A\":\n",
    "                return 'cyan'\n",
    "            else:\n",
    "                return 'pink'\n",
    "\n",
    "        color = dict((i, color(i)) for i in self.network.nodes())\n",
    "        # if self.network_type == \"ring\":\n",
    "        pos = nx.circular_layout(self.network)\n",
    "        #\n",
    "        # else:\n",
    "        #     pos = nx.spring_layout(self.network)\n",
    "\n",
    "        nx.draw_networkx_edges(self.network, pos)\n",
    "        nx.draw_networkx_nodes(self.network, pos, node_color=list(color.values()), node_size=500)\n",
    "        labels = {}\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if focal.type == \"+\":\n",
    "                labels[index] = f\"{index},+\"\n",
    "            else:\n",
    "                labels[index] = f\"{index},-\"\n",
    "\n",
    "        nx.draw_networkx_labels(self.network, pos, labels, font_size=16)\n",
    "        eq_str = \"\"\n",
    "        if equilibrated:\n",
    "            eq_str = \"Equilibrated!\"\n",
    "        plt.title(f\"t={timestep}  {eq_str}\", fontsize=20)\n",
    "        plt.axis = \"off\"\n",
    "        time_past_eq = -1\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(f\"snap_t={timestep}.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def has_equilibrated(self):\n",
    "        equilibrated = 1\n",
    "        for index, focal in enumerate(self.agents):\n",
    "            if focal.strategy != focal.previous_strategy:\n",
    "                equilibrated = 0\n",
    "                break\n",
    "\n",
    "        return equilibrated\n",
    "\n",
    "    def one_episode(self, time_steps, threshold):\n",
    "        reached_desired = 0\n",
    "        self.__initialize_label_A_or_B()\n",
    "        self.determine_coordinator_or_anticoordinator(self.type_list)\n",
    "        equilibrated = -1\n",
    "        equilibrated_array = []\n",
    "        current_strategy_list = self.strategy_list\n",
    "        prev_i = -2\n",
    "        for t in range(time_steps):\n",
    "            print(\"current: \"+str(current_strategy_list ) )\n",
    "                  \n",
    "#             for f in self.agents:\n",
    "#                 print(\"id: \"+ str(f.id)+\" type: \"+f.type+\" strategy: \"+f.strategy+\" willing to be: \"+str(f.next_strategy))\n",
    "            for i in range(self.population):\n",
    "                self.agents[i].previous_strategy = self.agents[i].strategy\n",
    "                # if(t == time_steps-1):\n",
    "                \n",
    "                (self.agents[i]).decide_next_strategy(self.agents, self.Z_func, threshold)\n",
    "#                 print(\"next strategy in this timestep is decided for everyone!\")\n",
    "                current_strategy_list[i] = self.agents[i].strategy\n",
    "                reached_desired = (self.strategy_list == current_strategy_list)\n",
    "            # RANDOM AGENT TO BE ACTIVATED\n",
    "            # index_list = rnd.sample(range(self.population), k = 1)#########GGG#####\n",
    "            # index = index_list[0]\n",
    "            # AGENT TO BE ACTIVATED UNDER OUR POLICY:\n",
    "            index = self.activate_policy(prev_i)\n",
    "            prev_i = index\n",
    "            print(\"in timestep \"+str(t)+\" selected: agent \"+str(index))\n",
    "            \n",
    "            # if index!=0 and index!= self.population-1:\n",
    "            if index != -1:\n",
    "                # for index in self.cooperators: (everybody is cooperating)\n",
    "#                 (self.agents[index]).decide_next_strategy(self.agents, self.Z_func, threshold)\n",
    "#                 print(\"selected agent next strategy: \"+self.agents[index].next_strategy )\n",
    "                # for index in self.cooperators:\n",
    "                (self.agents[index]).update_strategy()\n",
    "                # self.agents[index].next_strategy = (self.agents[index]).strategy\n",
    "            else:\n",
    "                print (\"no one found\\n\")\n",
    "                if self.has_equilibrated():\n",
    "                    print(\"final:   \"+str(current_strategy_list ) )\n",
    "                    break\n",
    "#                 else:\n",
    "#                 self.activated_list = np.zeros(self.population)\n",
    "            equilibrated = self.has_equilibrated()\n",
    "            self.__take_snapshot(t, equilibrated)\n",
    "            print(\"selected agent : \"+str(index))\n",
    "            equilibrated_array.append(equilibrated)\n",
    "        eq_time = -1\n",
    "\n",
    "        new_result = pd.DataFrame(\n",
    "            {'reached_desired?': [reached_desired], 'Equilibrated?': [equilibrated], 'types': [self.type_list],\n",
    "             'initial strategy set': self.initial_string, 'final strategy set': [current_strategy_list],\n",
    "             'equilibration time': [eq_time]})\n",
    "        return new_result, equilibrated, eq_time, reached_desired\n",
    "\n",
    "    def activate_policy(self,prev_i):\n",
    "        c1 = []\n",
    "        c2 = []\n",
    "        c3 = []\n",
    "        for agent in self.agents:\n",
    "            w = (agent.strategy == self.desired_eq[agent.id])\n",
    "            B = (agent.strategy != agent.next_strategy)\n",
    "#             print(\"w=\"+str(w),\"B = \"+str(B))\n",
    "            if B == 1:\n",
    "                if agent.strategy == 'B' and agent.type == '+' \\\n",
    "                        and (self.strategy_list[plus(agent.id, 1, self.population)] == 'A' \\\n",
    "                             or self.strategy_list[\n",
    "                                 minus(agent.id, 1, self.population)] == 'A'):  # if agent[i+1]= A or agent[i-1] = A:\n",
    "                    c3.append(agent.id)  # add agent i to c3\n",
    "                elif (agent.strategy == 'B') and \\\n",
    "                     ((self.strategy_list[plus(agent.id, 1, self.population)] == 'B' and \\\n",
    "                       self.type_list[plus(agent.id, 1, self.population)] == '-' and \\\n",
    "                       self.strategy_list[plus(agent.id, 2, self.population)] == 'A' and \\\n",
    "                       self.type_list[plus(agent.id, 2, self.population)] == '-') or \\\n",
    "                      (self.strategy_list[minus(agent.id, 1, self.population)] == 'B' and \\\n",
    "                       self.type_list[minus(agent.id, 1, self.population)] == '-' and \\\n",
    "                       self.strategy_list[minus(agent.id, 2, self.population)] == 'A' and \\\n",
    "                       self.type_list[minus(agent.id, 2,\n",
    "                       self.population)] == '-')):  # else if (agent[i+1] = B- and agent[i+2] = A-) or (agent[i-1] = B- and agent[i-2] = A-):\n",
    "                    c3.append(agent.id)  # add agent i to c3\n",
    "                elif (agent.strategy == 'A' and agent.type == '-') and \\\n",
    "                        ((self.strategy_list[plus(agent.id, 1, self.population)] == 'A' and \\\n",
    "                          self.type_list[plus(agent.id, 1, self.population)] == '-') or \\\n",
    "                         (self.strategy_list[minus(agent.id, 1, self.population)] == 'A' and \\\n",
    "                          self.type_list[minus(agent.id, 1, self.population)] == '-')) :\n",
    "                    c3.append(agent.id)  # else if agent i = A- and(agent i+1 = A- or agent i-1 = A-)\n",
    "                    # add agent i to c3\n",
    "                else:\n",
    "                    if w == 0:\n",
    "                        c1.append(agent.id)\n",
    "                    elif agent.type == '+':\n",
    "                        c2.append(agent.id)\n",
    "#         for f in c3:\n",
    "#             if w==1:\n",
    "#                 c3.drop(f)\n",
    "        print(\"c1: \"+str(c1)+\" c2: \"+str(c2)+\" c3: \"+str(c3))\n",
    "        print(\"agents activated so far: \"+ str(self.activated_list))\n",
    "        for i in range(self.population):\n",
    "            if i in c1 and i!= prev_i:\n",
    "                self.activated_list[i] =self.activated_list[i]+ 1\n",
    "                return i\n",
    "        for i in range(self.population):\n",
    "            if i in c2 and self.activated_list[i] <= 2 and i!= prev_i:\n",
    "                self.activated_list[i] =self.activated_list[i]+ 1\n",
    "                return i\n",
    "        for i in range(self.population):\n",
    "            if i in c3 and i!= prev_i and self.activated_list[i] <= 3:\n",
    "                self.activated_list[i] =self.activated_list[i]+ 1\n",
    "                return i\n",
    "            \n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29964406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: ['B', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [3, 6] c2: [] c3: [0, 9, 11, 12, 13, 15, 16]\n",
      "agents activated so far: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 0 selected: agent 3\n",
      "selected agent : 3\n",
      "current: ['B', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [6] c2: [] c3: [0, 2, 9, 11, 12, 13, 15, 16]\n",
      "agents activated so far: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 1 selected: agent 6\n",
      "selected agent : 6\n",
      "current: ['B', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [] c3: [0, 2, 5, 7, 9, 11, 12, 13, 15, 16]\n",
      "agents activated so far: [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 2 selected: agent 0\n",
      "selected agent : 0\n",
      "current: ['B', 'A', 'A', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [] c3: [2, 5, 7, 9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 3 selected: agent 2\n",
      "selected agent : 2\n",
      "current: ['A', 'A', 'A', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [] c3: [5, 7, 9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 4 selected: agent 5\n",
      "selected agent : 5\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [] c3: [6, 7, 9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 5 selected: agent 6\n",
      "selected agent : 6\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 6 selected: agent 5\n",
      "selected agent : 5\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [6] c2: [] c3: [9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 7 selected: agent 6\n",
      "selected agent : 6\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [] c3: [5, 7, 9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 2. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 8 selected: agent 5\n",
      "selected agent : 5\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [] c3: [6, 7, 9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 9 selected: agent 6\n",
      "selected agent : 6\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [9, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 10 selected: agent 9\n",
      "selected agent : 9\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [8, 11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 11 selected: agent 8\n",
      "selected agent : 8\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [11, 12, 13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 12 selected: agent 11\n",
      "selected agent : 11\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [13, 15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "in timestep 13 selected: agent 13\n",
      "selected agent : 13\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "in timestep 14 selected: agent 15\n",
      "selected agent : 15\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5, 14] c3: [17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "in timestep 15 selected: agent 14\n",
      "selected agent : 14\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A']\n",
      "c1: [15] c2: [5] c3: [17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.]\n",
      "in timestep 16 selected: agent 15\n",
      "selected agent : 15\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [14, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 1. 2. 0. 0.]\n",
      "in timestep 17 selected: agent 14\n",
      "selected agent : 14\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'B', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 2. 2. 0. 0.]\n",
      "in timestep 18 selected: agent 15\n",
      "selected agent : 15\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5, 14] c3: [17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 2. 3. 0. 0.]\n",
      "in timestep 19 selected: agent 14\n",
      "selected agent : 14\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A']\n",
      "c1: [15] c2: [5] c3: [17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 3. 3. 0. 0.]\n",
      "in timestep 20 selected: agent 15\n",
      "selected agent : 15\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [14, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 3. 4. 0. 0.]\n",
      "in timestep 21 selected: agent 14\n",
      "selected agent : 14\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'B', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: [15, 16, 17]\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 4. 4. 0. 0.]\n",
      "in timestep 22 selected: agent 16\n",
      "selected agent : 16\n",
      "current: ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A']\n",
      "c1: [] c2: [5] c3: []\n",
      "agents activated so far: [1. 0. 1. 1. 0. 3. 4. 0. 1. 1. 0. 1. 0. 1. 4. 4. 1. 0.]\n",
      "in timestep 23 selected: agent -1\n",
      "no one found\n",
      "\n",
      "final:   ['A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A']\n",
      "desired: ['A', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A']\n",
      "init:    ['B', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "type:    ['+', '+', '-', '-', '-', '+', '-', '-', '-', '+', '+', '-', '-', '-', '+', '-', '-', '-']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3542/3181970429.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result = result.append(new_result)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from numpy import zeros\n",
    "import random\n",
    "import  pandas as pd\n",
    "import itertools\n",
    "from pandas import concat\n",
    "\n",
    "\n",
    "def main():\n",
    "    population = 18 # number of agents\n",
    "    num_episode = 1    # Number of total episode in a single simulation for taking ensemble average\n",
    "    time_steps =30\n",
    "    threshold = 1/2\n",
    "    Z_func = \"A\" # the next strategy if number of A-playing neighbors equlas B-playing ones\n",
    "    always_equilibrates = 1\n",
    "    global new_result\n",
    "    result = pd.DataFrame({'reached_desired?': [],'Equilibrated?': [],'types': [],'initial strategy set': [],'final strategy set': [],'equilibration time': []})\n",
    "    # algorithm works on:\n",
    "    desired_eq =       ['A', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A','A', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A'] #desired equilibrium strategy of the agents\n",
    "    type_list =        ['-', '-', '-', '+', '+']#coordinator or anticoordinator listed identified by + and - signs\n",
    "    initial_strategy  = ['A', 'A', 'A', 'B', 'B']#initial strategy of the agents\n",
    "    init = str(initial_strategy)\n",
    "\n",
    "    #it also works on: (original example ;))\n",
    "#     desired_eq = ['A', 'B', 'A', 'A', 'B', 'A', 'A', 'A']  # desired equilibrium strategy of the agents\n",
    "#     type_list = ['+', '-', '-', '+', '-', '-', '+', '+']  # coordinator or anticoordinator listed identified by + and - signs\n",
    "#     initial_strategy = ['B', 'B', 'B', 'B', 'B', 'B', 'B','B']  # initial strategy of the agents# selection = [i for i in range(population)]\n",
    "\n",
    "    # selection = [i for i in range(population)]\n",
    "    activated_list = zeros(population)\n",
    "    simulation = Simulation(population, Z_func, initial_strategy, type_list,activated_list, desired_eq,init)\n",
    "    new_result,equilibrated,eq_time,reached_desired = simulation.one_episode(time_steps, threshold)\n",
    "#     result = pd.DataFrame.from_records\n",
    "    result = result.append(new_result)\n",
    "    result.to_csv(f\"newfile.csv\")\n",
    "    \n",
    "    print(\"desired: \"+ str(desired_eq))\n",
    "    print(\"init:    \"+init)\n",
    "    print(\"type:    \"+str(type_list))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "# focus on the number of times one agent must be allowed to be activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0003d130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3d756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
